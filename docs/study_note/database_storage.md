## 数据库存储

### mmap和操作系统的缺陷

1.页面置换可能发生在正在访问的内存中（操作系统控制而不是用户）

2.写入磁盘时的顺序问题步伐保证（仍然是由操作系统控制而不是用户）

综上所述，由于需要做一些额外的事情（哪些可以让操作系统去做，哪些不行），来防止操作系统做一些错误的事情，需要用缓存来处理该问题，所以需要缓存池

### 问题1:如何表示磁盘上文件中的数据

1.基于操作系统的文件系统来管理数据，或者是自己手动管理硬盘（也就是自研文件系统，oracle，db2，sqlserver都在这么做，这样可以提升约10%的性能，但是可能导致无法移植）

2.存储管理器，存储引擎：负责维护磁盘上的数据库文件（部分数据库会在文件系统上有一个shim层，优化或者提升性能）

3.page中一般不会保存所有的信息（例如数据，日志和索引一般都不会放在同一个page中）

4.indirection层

5.page大小：hardware page一般为4kb（硬件，存储设备只能保证hardware page的大小是原子的）；OS page一般为4kb；database page一般在512B-16kb

6.统一管理所有的page（也就是元数据）

7.checksum:crc或者md5

8.page head:page大小，checksum，dbms版本之类的东西

9.page内部:header-tuple指针-tuple，header在最前面（包括某某tuple是否存在），tuple指针（又叫slot array）紧跟其后，tuple从page末尾往前进行填充

10.一般来说，同一个page中只会表示同一张表的数据

11.识别tuple的方式是通过record id或者是tuple id来做到的（id为唯一），然后通过id进行偏移，找到唯一的数据

12.反范式化:将不同的表数据存储在同一个page中（一般存储的是有关联的表，例如通过外键进行关联）

13.日志存储，又叫日志结构文件，多用于分布式数据库:数据通过修改日志（insert，update，select和delete）来存储，不存储特定的数据，仅日志。读取缺陷比较大（可以通过索引提高读取性能）

14.变长变量:有一个head来表示长度，然后紧跟一个checksum，最后才是实际的数据

15.时间:时间戳

16.浮点数:IEEE-754标准

17.由于IEEE-754标准无法存储一个十进制的小数，无法精确表达浮点数，所以需要固定浮点数（小数点，精度范围，四舍五入信息                                                                                                          ）来处理

18.一个tuple非常大（超过2k），一个page无法放下怎么办？解答:(1)使用overflow pages（sql server和mysql里这样叫），也就是用一个指针来指向内容(2)使用外部存储，也就是将数据放在网络磁盘或者本地磁盘上，通过指针或者文件路径来寻找该数据，但是你无法修改这种较大的数据，并且需要做一些特殊的缓存操作，否则会占用大量的缓存(3)overflow page对用户来说是透明的

### 问题2:如何管理内存，以及在硬盘间来回移动数据

1.存储模型

2.N-ARY STORAGE MODEL(NSM):会对对tuple进行对齐，连续排列。也就是比较传统的存储模型，用指针，用tuple，用overflowpage。这种存储模型在插入，更新，以及删除数据的时候效率较高，但是在查询时，有时候会把page中一些用不到的列数据也会一并加载到内存中，也就是获取tuple中的指定列，所以会导致查询效率在数据量较大的情况下，效率低下。这就是列存储解决的痛点:不将单个tuple的全部属性放在单个page上，而是将tuple中单个属性的所有值保存在单个pgae上

3.列存储对于OLAP(联机分析处理)有很大的优势，查询优势较大。并且列存储易于压缩，因为在同一个属性中，可能有大量的重复数据

4.对于，列存储，如何跨page进行查询:(1)最常见的是使用固定偏移量进行查询，也就是offsets(2)使embedded lds，也就是对于每个值，为其保存一个主键或者标识符，缺点是会有大量的存储开销

5.列存储的缺陷是在读取一个完整的tuple的时候效率会很低，并且在插入，更新，删除的时候效率也会很低

6.OLTP=row Store 行存储，OLAP=column Store 列存储


### buffer pools

如何管理内存并比os来得更好

1.需要用一个flag来记录，存在内存池中的page是否被修改过

2.需要分区，page目录(需要持久化)和page表(不用持久化，但是要是线程安全的)

3.全局策略(对于全局来说)和局部策略(对于单个查询或者事物来说)

4.可以有多个buffer pool，对单个buffer pool采用局部策略

5.通过hash来查找page在哪个buffer pool中

6.通过预读来提高效率，减少停顿的产生，前提是知道用户要干什么，也就是知道查询要干什么，去做预读，这里就是和操作系统的mmap有区别的地方，可以通过自定义要求进行预读

7.扫描共享，一次io，将数据应用到多个查询中(前提是多个查询需要使用相同的数据，类似订阅者和发布者)

8.buffer pool bypass:为某个查询单独分配线程和内存，不会影响到buffer pool，也就是通过额外的独立内存进行io，查询结束后进行释放，该过程完全独立于buffer pool，因为buffer pool有锁的开销，可能此时你并不想增加额外的开销

9.因为buffer pool是通过os的接口来做的所有事情，所以在将磁盘的数据转移到buffer pool的时候，os层的缓存也会持有一份page的副本。所以如何去做呢？（怎么去实现Direct I/O）

10.替换策略:商用数据库的替换策略是非常复杂的例如引用计数，然后计算权重等等，开源数据库可能非常简易(1)LRU最近最久未使用(2)Clocks算法:通过一个环形队列，用指针检查所有page的flag(为0:在上次检查过后，该page没有被访问，可以被换出。初始都是0，查询使用的时候将page置为1。在需要换出的时候，轮训查找，将找到的1变为0，第一个0换出，指针会停留在最近移出的那个page上，当然，这也是环形队列的好处)(3)LRU-K:k是指需要对个单个page对应缓存数据的访问进行计数的次数，也就是对page的访问计数积累(4)优先级提示:例如某些树节点需要长期驻留在内存中，通过这些节点去找到叶子page

11.如何处理dirty page？也就是在buffer pool中加载的page已经被修改，如何进行处理？方法一是找到未被修改的page进行置换，方法二是将其安全的写回磁盘。方法一和替换策略会有一些冲突，比如未被修改的page可能频繁被使用，这时候可能使用到方法二对dirty page进行操作

12.通过定时任务对dirty page进行操作，将其在后台写回到磁盘中，将dirty page变为clean page。（先写日志，再写入磁盘）

### Hash Tables

